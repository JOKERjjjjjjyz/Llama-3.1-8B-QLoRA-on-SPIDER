{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spider SFT Data Prep\n",
        "Build instruction-tuning data (messages + text) from Spider train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d73df785",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "484daa82",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = Path('/home/geniusjjjjj/data/spider')\n",
        "# TRAIN_JSON = DATA_DIR / 'train_spider.json'\n",
        "TRAIN_JSON = DATA_DIR / 'dev.json'\n",
        "TABLES_JSON = DATA_DIR / 'tables.json'\n",
        "\n",
        "OUT_DIR = Path('/home/geniusjjjjj/transformer/SFT/data')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_JSONL = OUT_DIR / 'spider_dev_sft.jsonl'\n",
        "\n",
        "# Optional: limit size for a quick smoke test\n",
        "MAX_SAMPLES = None  # e.g. 1000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a4c31fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = json.loads(TRAIN_JSON.read_text())\n",
        "tables = {t['db_id']: t for t in json.loads(TABLES_JSON.read_text())}\n",
        "\n",
        "def schema_to_text(db_id):\n",
        "    t = tables[db_id]\n",
        "    table_names = t['table_names_original']\n",
        "    column_names = t['column_names_original']\n",
        "\n",
        "    cols_by_table = {i: [] for i in range(len(table_names))}\n",
        "    for tbl_idx, col in column_names:\n",
        "        if tbl_idx == -1:\n",
        "            continue\n",
        "        cols_by_table[tbl_idx].append(col)\n",
        "\n",
        "    parts = []\n",
        "    for i, tbl in enumerate(table_names):\n",
        "        cols = ', '.join(cols_by_table[i])\n",
        "        parts.append(f\"{tbl}({cols})\")\n",
        "    return ' ; '.join(parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0189729f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_system_prompt() -> str:\n",
        "    return (\n",
        "        \"You are a text-to-SQL system.\\n\"\n",
        "        \"Use ONLY tables/columns from the schema.\\n\"\n",
        "        \"Return exactly ONE SQLite SQL query and nothing else.\\n\"\n",
        "        \"Do NOT include explanations, comments, code fences, or the database id.\"\n",
        "    )\n",
        "\n",
        "def build_user_prompt(question: str, db_id: str) -> str:\n",
        "    schema = schema_to_text(db_id)\n",
        "    return (\n",
        "        f\"Database id: {db_id}\\n\"\n",
        "        f\"Schema: {schema}\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        \"SQL:\"\n",
        "    )\n",
        "\n",
        "def build_example(ex):\n",
        "    db_id = ex[\"db_id\"]\n",
        "    question = ex[\"question\"]\n",
        "    gold_sql = ex[\"query\"]\n",
        "\n",
        "    system = build_system_prompt()\n",
        "    user = build_user_prompt(question, db_id)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "        {\"role\": \"assistant\", \"content\": gold_sql},\n",
        "    ]\n",
        "\n",
        "    # Plain text fallback (kept consistent with system+user framing).\n",
        "    # If you later decide to train from `text` instead of `messages`,\n",
        "    # this will better match the chat-template distribution.\n",
        "    text = system + \"\\n\\n\" + user + \"\\n\" + gold_sql\n",
        "\n",
        "    return {\n",
        "        \"db_id\": db_id,\n",
        "        \"question\": question,\n",
        "        \"gold_sql\": gold_sql,\n",
        "        \"messages\": messages,\n",
        "        \"text\": text,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /home/geniusjjjjj/transformer/SFT/data/spider_dev_sft.jsonl\n",
            "Samples: 1034\n"
          ]
        }
      ],
      "source": [
        "# Build and save dataset\n",
        "count = 0\n",
        "with OUT_JSONL.open('w', encoding='utf-8') as f:\n",
        "    for ex in train_data:\n",
        "        if MAX_SAMPLES is not None and count >= MAX_SAMPLES:\n",
        "            break\n",
        "        item = build_example(ex)\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "        count += 1\n",
        "\n",
        "print('Wrote:', OUT_JSONL)\n",
        "print('Samples:', count)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "transformer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
